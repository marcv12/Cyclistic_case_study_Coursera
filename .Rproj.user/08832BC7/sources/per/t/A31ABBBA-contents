library(caret)
library(dplyr)
library(GGally)
library(ggplot2)
library(tidyverse)
library(corrplot)
library(gridExtra)
library(ggpubr)
library(moments)
library(rpart)
library(rpart.plot)
library(pROC)
library(AUC)
library(glmnet)
library(C50)
library(randomForest)
library(boot)
library(doParallel)
library(leaps)
library(gam)
library(stats)


#Ignore this function, I use this when caret has an issue
unregister_dopar <- function() {
  env <- foreach:::.foreachGlobals
  rm(list=ls(name=env), pos=env)
}


df <- read.csv(file = "WineQuality.csv", 
                     header=T,
                     sep=",",
                     dec=".",
                     stringsAsFactors = T)

df %>% map(~ sum(is.na(.)))
#Wonderful, no null values


#Understanding the variables:
#1)Residual sugar: the amount of sugar left after the fermentation stops
#2)pH: The level of acidity
#3)Free sulfur dioxide: prevents microbial growth and the oxidation of wine
#4)Fixed acidity: non-volatile acids that do not evaporate immediately
#5)Density: the sweeter the wine, the higher density
#6)Chlorides: the amount of salt in the wine
#7)Alcohol: we all know what it is...
#8)Volatile acidity: leads to unpleasant vinegar taste
#9)Sulphates: a wine additive that contributes to SO2 levels 
#10)Total sulfur dioxide: Amount of free + bound forms of SO2
#11)Citric acid: acts as preservative to increase acidity

#Before starting our exploration phase, allow me to use some blatant outliers. 
#This step might be not necessary in your eyes because we are compromising a 
#significant number of data observations. However, these observations largely 
#interfere with the reality of the situation and the results will not be satisfactory.
#I have tried to do the experiment multiple times, fitting the algorithms to this
#dataset (once without the outliers and another time as it is), and there was a 
#clear improvement in performance when I had removed the outliers.

#For outlier cleaning, I have used Cook's distance as a metric as it allows me 
#to get rid of data points with a significant leverage.
table(df$quality)
# Get rid of outliers
outliers = c()
for ( i in 1:11 ) {
  stats = boxplot.stats(df[[i]])$stats
  bottom_outlier_rows = which(df[[i]] < stats[1])
  top_outlier_rows = which(df[[i]] > stats[5])
  outliers = c(outliers , top_outlier_rows[ !top_outlier_rows %in% outliers ] )
  outliers = c(outliers , bottom_outlier_rows[ !bottom_outlier_rows %in% outliers ] )
}

# #Detect/Remove outliers
# dim(df)
# mod = lm(quality ~ ., data = df)
# summary(mod)
# cooksd = cooks.distance(mod)
# lapply(1:6, function(x) plot(mod, which=x, labels.id= 1:nrow(df))) %>% invisible()
# abline(h = 20*mean(cooksd, na.rm = T), col = "red")
# head(df[cooksd > 20 * mean(cooksd, na.rm=T), ])
# coutliers = as.numeric(rownames(df[cooksd > 20 * mean(cooksd, na.rm=T), ]))
# outliers = c(outliers , coutliers[ !coutliers %in% outliers ] )
# df = df[-outliers, ]
# dim(df)
# mod = lm(quality ~ ., data = df)
# summary(mod)
# par(mfrow=c(2,3))
# lapply(1:6, function(x) plot(mod, which=x, labels.id= 1:nrow(df))) %>% invisible()


range(df$quality)
#values in population generally range on a scale from 0 to 10 but in our dataset 
#minimum is 3 and max is 9, so no exceptional or horrible wine.

table(df$quality)
#Very few have a quality of 9 and 3. Let's see a histogram of quality

str(df)
#Only numerical variables, all continuous except for quality (which is the 
#target variable)



#This makes our life easier in the univariate EDA, as we only have to draw 
#histograms!
p1 <- ggplot(df, aes(x=fixed.acidity)) + ggtitle("Fixed Acidity") + 
  xlab("Fixed acidity") + geom_histogram(fill="salmon")
p2 <- ggplot(df, aes(x=volatile.acidity )) + ggtitle("Volatile Acidity") + 
  xlab("Volatile acidity") + geom_histogram(fill="salmon") 
p3 <- ggplot(df, aes(x=citric.acid)) + ggtitle("Citric acid") + xlab("Citric acid") + 
  geom_histogram(fill="salmon") 
p4 <- ggplot(df, aes(x=residual.sugar)) + ggtitle("residual sugar") +
  xlab("residual sugar") + geom_histogram(fill="salmon")
grid.arrange(p1, p2, p3, p4, ncol=2)

p5 <- ggplot(df, aes(x=chlorides)) + ggtitle("Chlorides") + 
  xlab("Chlorides") + geom_histogram(fill="salmon")
p6 <- ggplot(df, aes(x=free.sulfur.dioxide )) + ggtitle("Free sulfur dioxide")+ 
  xlab("Free sulfur dioxide") + geom_histogram(fill="salmon") 
p7 <- ggplot(df, aes(x=total.sulfur.dioxide)) + ggtitle("Total sulfure dioxide") + xlab("Total sulfure dioxide") + 
  geom_histogram(fill="salmon") 
p8 <- ggplot(df, aes(x=pH)) + ggtitle("pH") + 
  xlab("pH") + geom_histogram(fill="salmon")
grid.arrange(p5, p6, p7, p8, ncol=2)

p9 <- ggplot(df, aes(x=sulphates)) + ggtitle("Sulphates") + 
  xlab("Sulphates") + geom_histogram(fill="salmon")
p10 <- ggplot(df, aes(x=alcohol )) + ggtitle("Alcohol")+ 
  xlab("alcohol") + geom_histogram(fill="salmon") 
p11 <- ggplot(df, aes(x=quality)) + ggtitle("Quality") + xlab("quality") + 
  geom_bar(fill="salmon") 
grid.arrange(p9, p10, p11, ncol=2)
grid.arrange(p4,p5,p6, ncol=2)
skewness(df$residual.sugar)
df <- df %>% mutate(residual.sugar = log(residual.sugar))
skewness(df$residual.sugar)

skewness(df$chlorides)
df <- df %>% mutate(chlorides = log(chlorides))
skewness(df$chlorides)

skewness(df$free.sulfur.dioxide)
df<- df %>% mutate(free.sulfur.dioxide = sqrt(free.sulfur.dioxide))
skewness(df$free.sulfur.dioxide)

#Check for correlation among variables
df %>% ggcorr()





#bivariate analysis:
g1 <- ggplot(df, aes(factor(quality), fixed.acidity, fill=factor(quality))) + 
  geom_boxplot() +
  labs(x = "quality", y = "fixed.acidity", title = "Boxplot of Quality vs. fixed.acidity") + 
  theme(legend.position = 'none', plot.title = element_text(size = 9, hjust=0.5))

g2 <- ggplot(df, aes(factor(quality), volatile.acidity, fill=factor(quality))) + 
  geom_boxplot() +
  labs(x = "quality", y = "volatile.acidity", title = "Boxplot of Quality vs. volatile.acidity") + 
  theme(legend.position = 'none', plot.title = element_text(size = 9, hjust=0.5))

g3 <- ggplot(df, aes(factor(quality), citric.acid, fill=factor(quality))) + 
  geom_boxplot() +
  labs(x = "quality", y = "citric.acid", title = "Boxplot of Quality vs. citric.acid") + 
  theme(legend.position = 'none', plot.title = element_text(size = 9, hjust=0.5))

g4 <- ggplot(df, aes(factor(quality), residual.sugar, fill=factor(quality))) + 
  geom_boxplot() +
  labs(x = "quality", y = "residual.sugar", title = "Boxplot of Quality vs. residual.sugar") + 
  theme(legend.position = 'none', plot.title = element_text(size = 9, hjust=0.5))
ggarrange(g1, g2, g3, g4, nrow = 2, ncol =2)


g5 <- ggplot(df, aes(factor(quality), chlorides, fill=factor(quality))) + 
  geom_boxplot() +
  labs(x = "Quality", y = "chlorides", title = "Boxplot of Quality vs. chlorides") + 
  theme(legend.position = 'none', plot.title = element_text(size = 9, hjust=0.5))

g6 <- ggplot(df, aes(factor(quality), free.sulfur.dioxide, fill=factor(quality))) + 
  geom_boxplot() +
  labs(x = "quality", y = "free.sulfur.dioxide", title = "Boxplot of quality vs. free.sulfur.dioxide") + 
  theme(legend.position = 'none', plot.title = element_text(size = 9, hjust=0.5))

g7 <- ggplot(df, aes(factor(quality), total.sulfur.dioxide, fill=factor(quality))) + 
  geom_boxplot() +
  labs(x = "quality", y = "total.sulfur.dioxide", title = "Boxplot of quality vs. total.sulfur.dioxide") + 
  theme(legend.position = 'none', plot.title = element_text(size = 9, hjust=0.5))

g8 <- ggplot(df, aes(factor(quality), density, fill=factor(quality))) + 
  geom_boxplot() +
  labs(x = "quality", y = "density", title = "Boxplot of quality vs. density") + 
  theme(legend.position = 'none', plot.title = element_text(size = 9, hjust=0.5))
ggarrange(g5, g6, g7, g8, nrow = 2, ncol =2)


g9 <- ggplot(df, aes(factor(quality), pH, fill=factor(quality))) + 
  geom_boxplot() +
  labs(x = "quality", y = "pH", title = "Boxplot of Quality vs. pH") + 
  theme(legend.position = 'none', plot.title = element_text(size = 9, hjust=0.5))

g10 <- ggplot(df, aes(factor(quality), sulphates, fill=factor(quality))) + 
  geom_boxplot() +
  labs(x = "quality", y = "sulphates", title = "Boxplot of quality vs. sulphates") + 
  theme(legend.position = 'none', plot.title = element_text(size = 9, hjust=0.5))

g11 <- ggplot(df, aes(factor(quality), alcohol, fill=factor(quality))) + 
  geom_boxplot() +
  labs(x = "quality", y = "alcohol", title = "Boxplot of quality vs. alcohol") + 
  theme(legend.position = 'none', plot.title = element_text(size = 9, hjust=0.5))
ggarrange(g9, g10, g11, nrow = 2, ncol =2)


#split data into train/test set
p=ncol(df)
train_index <- createDataPartition(df$quality, p = .9, 
                                   list = FALSE, 
                                   times = 1)
traintot <- df[train_index, ]
test <- df[-train_index, ]

trainScalenum <- traintot %>% select(-p) %>%  scale()
trainScale <- cbind(trainScalenum, quality=traintot[,p]) 
trainScale
testScalenum <- test %>% select(-p) %>% scale(., center=attr(trainScalenum, "scaled:center"),
                                                           scale=attr(trainScalenum, "scaled:scale"))
testScale <- cbind(testScalenum, quality=test[,p])

trainScale <- data.frame(trainScale)
testScale <- data.frame(testScale)

#Split train in train/validation set
train_index2 <- createDataPartition(trainScale$quality, p = .8, 
                                   list = FALSE, 
                                   times = 1)
trainScaled <- trainScale[train_index2, ]
validationScaled <- trainScale[-train_index2, ]



trainScaled <- data.frame(trainScaled)
validationScaled <- data.frame(validationScaled)




#Let's start easy with a linear regression to understand how pH and alcohol affect 
#the quality and each other.
lm.fit = lm(quality~., data = trainScaled)
summary(lm.fit)
trainScaled




#Function that will allow us to easily evaluate our models based on specific 
#metrics. This will allow us to have a similar comparison at the end between the 
#different models
myval = function(pred, actual,title= "") {
  rmse = sqrt(mean((pred - actual)^2))
  mae = mean(abs(pred - actual))
  cor = cor(pred, actual)
  par(mfrow = c(1,3), oma = c(0, 0, 3, 0))
  resid = pred - actual
  plot(resid)
  plot(jitter(actual, factor = 1), 
       jitter(pred, factor = 0.5), 
       pch = 4, asp = 1,
       xlab = "Truth", ylab = "Predicted") 
  abline(0,1, lty = 2)
  hist(resid, breaks = 20, main = NULL)
  mtext(paste0(title, " predicted vs. actual using test set"), outer = TRUE)
  par(mfrow = c(1,1))
  return(list(rmse = rmse,
              mae = mae,
              cor = cor
              
              ))
}

lm.fit = lm(quality~., data = trainScaled)
summary(lm.fit)
#We see that R-squared is so low so our model doesn't capture variability of 
#dependent variable.

lm.pred = predict(lm.fit, validationScaled[,-p])
tr.lm.myval = myval(lm.pred, validationScaled$quality, title = "linear model: predicted vs true"); unlist(tr.lm.myval)
#Difference between predicted and true quality is not too bad.



#Real talk, start fitting models
myfirstfit = lm(quality~alcohol*pH, data=trainScaled)
summary(myfirstfit)

#Let's analyze what we get:
#Suppose X1: alcohol, X2: pH
#model is: b0 + b1(X1)' + b2(X2)' + b3(X1)'(X2)'
#b0 = 5.94: This is E(Y) when pH and alcohol are set to their respective means
#b1 = 0.36: This is E(ΔY) when (X2)' = 0 so when pH is equal to its mean
#and when alcohol increases by 1 standard deviation we expect an increase in quality 
#of 0.36, which is not negligible at all
#b1 + b3 = 0.1 : This is E(ΔY) when (X2)' = 1 so when pH = mean(pH)+sd(pH)
#and when alcohol increases by one sd, we expect an increase in quality of 0.44.
#This improves slightly on the effect caused by increasing alcohol by 1 sd, but it 
#is clear that most of the increase comes from alcohol rather than from the interaction
#between pH and alcohol.
#Lastly, when (X2)' = -1, so when pH = mean(pH)-sd(pH) and when alcohol increases by 
#one sd, we get b1-b3 = 0.28, which means that we expect an increase in quality
#of 0.28. As mentioned before, we observe that alcohol is the main driving force




# variable selection using stepwise methods
lm0 = lm(quality ~ ., data = trainScaled)
tr.lm.interract.step = step(lm0, ~ (fixed.acidity + volatile.acidity + 
                                      citric.acid + residual.sugar +  chlorides + free.sulfur.dioxide +
                                      total.sulfur.dioxide + density + pH + sulphates + alcohol)^2, 
                            direction = "both",trace = 0)
summary(tr.lm.interract.step)

tr.lm.interract.step.pred = predict(tr.lm.interract.step, validationScaled[,-p])
tr.lm.interract.step.myval = myval(tr.lm.interract.step.pred, validationScaled$quality, title="stepwise model: predicted vs true");unlist(tr.lm.interract.step.myval)


#LASSO + Elastic net + Ridge
dat = traintot %>% as_tibble()
X <- model.matrix(quality~.-1, data = dat)
Y <- dat$quality


n <- nrow(dat)
#Let's resplit to satisy format of lasso
ntr <- round(n*0.8)
nte <- n-ntr
trIdx <- sample(1:n, size=ntr)
Xtr <- X[trIdx,]
Ytr <- Y[trIdx]
Xte <- X[-trIdx,]
Yte <- Y[-trIdx]
XtrS <- Xtr %>% scale()   # Standardize
XteS <- Xte %>% scale(., center=attr(XtrS, "scaled:center"),
                            scale=attr(XtrS, "scaled:scale"))


nlambdas <- 100
lambdas <- seq(0.001, 2, length.out = nlambdas)
nfolds <- 5

#Lasso model
# Lasso.cv <- cv.glmnet(XtrS, Ytr, lambda=lambdas, alpha=1,
#                       family="gaussian")
# plot(Lasso.cv)
# 
# 
# lambdaStar <- Lasso.cv$lambda.1se
# tr.lasso.pred = predict(Lasso.cv, XteS, s=lambdaStar)
# tr.lasso.myval = myval(tr.lasso.pred, Yte, title="lasso model: predicted vs true"); unlist(tr.lasso.myval)
# 


#Ridge model
# Ridge.cv <- cv.glmnet(XtrS, Ytr, lambda=lambdas, alpha=0,
#                       family="gaussian")
# plot(Ridge.cv)
# 
# 
# lambdaStar <- Ridge.cv$lambda.1se
# tr.ridge.pred = predict(Ridge.cv, XteS, s=lambdaStar)
# tr.ridge.myval = myval(tr.ridge.pred, Yte, title="Ridge model: predicted vs true"); unlist(tr.ridge.myval)



#Elastic

unregister_dopar()

nalphas <- 20
alphas <- seq(0, 1, length.out=nalphas)
ctrl <- trainControl(method="cv", number=nfolds)
elastic.caret <- caret::train(XtrS, Ytr, method = "glmnet", trControl = ctrl,
                     tuneGrid = expand.grid(alpha = alphas, 
                                            lambda = lambdas))
best_alpha = elastic.caret$bestTune$alpha
best_lambda = elastic.caret$bestTune$lambda

tr.elastic.pred = predict(elastic.caret, XteS, s=best_lambda, a = best_alpha)
tr.elastic.myval = myval(tr.elastic.pred, Yte, title="elastic model: predicted vs true"); unlist(tr.elastic.myval)

#Let's run a decision tree algorithm

tr.rpart = rpart(quality~., data=trainScaled)
rpart.plot(tr.rpart)  
tr.rpart.pred = predict(tr.rpart, validationScaled[,-p])
tr.rpart.myval = myval(tr.rpart.pred, validationScaled$quality, title="decision tree: predicted vs true"); unlist(tr.rpart.myval)
# tree.quality = tree(quality~., data=trainScaled)
# cv.tree.quality = cv.tree(tree.quality)
# plot(cv.tree.quality, FUN=prune.tree)
# prune.tree = prune.tree(tree.quality, best=5)
# tree.pred = predict(prune.tree, validationScaled[,-p])
# tr.rpart.myval = myval(tree.pred, validationScaled$quality, title="decision tree: predicted vs true"); unlist(tr.rpart.myval)

# fit a random forest model

tr.rf= randomForest(quality~., data=trainScaled, ntree=1000, mtry=3)
tr.rf


#evaluate RF on test
tr.rf.pred = predict(tr.rf, validationScaled[,-p])
tr.rf.myval = myval(tr.rf.pred, validationScaled$quality, title="random forest: predicted vs true"); unlist(tr.rf.myval)


#RF with CV

ct = trainControl(method = "repeatedcv", number = 10, repeats = 2)
grid_rf = expand.grid(.mtry = c(3, sqrt(p), p/3))

tr.cvrf = train(quality~., data = trainScaled,
                method = 'rf',
                metric = "RMSE",
                trControl = ct,
                tuneGrid = grid_rf)
tr.cvrf.pred = predict(tr.cvrf, validationScaled[,-p])
tr.cvrf.myval = myval(tr.cvrf.pred, validationScaled$quality, title="rf with CV: predicted vs true"); unlist(tr.cvrf.myval)


#xgboost
# fitControl = trainControl(
#   method = "repeatedcv",
#   number = 5, 
#   search="random")
# 
# tune_grid = 
#   expand.grid(
#     nrounds = c(50, 70, 90, 110),
#     eta = c(0.03,0.3),
#     max_depth=c(5,7,9),
#     subsample = c(0.5, 0.75, 1),
#     colsample_bytree = c(0.6, 0.8, 1),
#     min_child_weight = 5,
#     gamma = c(0.05, 0.2, 0.5, 1)
#   )
unregister_dopar()
# fit_xg_cv = caret::train(quality ~ ., data = trainScaled, 
#                   method = "xgbTree", 
#                   trControl = fitControl,
#                   tuneGrid = tune_grid,
#                   objective = "reg:squarederror", 
#                   eval_metric = "rmse")
# fit_xg_cv
# plot(fit_xg_cv)  

# pred_xg_cv = predict(fit_xg_cv, validationScaled[,-p])
# tr.xg.pred = predict(fit_xg_cv, validationScaled[,-p])
# tr.xg.myval = myval(tr.xg.pred, validationScaled$quality, title="random forest: predicted vs true"); unlist(tr.rf.myval)

#Finding best params for boosting
# note to start nrounds from 200, as smaller learning rates result in errors so
# big with lower starting points that they'll mess the scales

nrounds = 1000
tune_grid <- expand.grid(
  nrounds = seq(from = 200, to = nrounds, by = 50),
  eta = c(0.025, 0.05, 0.1, 0.3),
  max_depth = c(2, 3, 4, 5, 6),
  gamma = 0,
  colsample_bytree = 1,
  min_child_weight = 1,
  subsample = 1
)

tune_control <- caret::trainControl(
  method = "cv", # cross-validation
  number = 3, # with n folds 
  #index = createFolds(tr_treated$Id_clean), # fix the folds
  verboseIter = FALSE, # no training log
  allowParallel = TRUE # FALSE for reproducible results 
)

xgb_tune <- caret::train(
  quality ~ ., data = trainScaled,
  trControl = tune_control,
  tuneGrid = tune_grid,
  method = "xgbTree",
  objective = "reg:squarederror", 
  eval_metric = "rmse",
  verbose = TRUE
)

# helper function for the plots
tuneplot <- function(x, probs = .90) {
  ggplot(x) +
    coord_cartesian(ylim = c(quantile(x$results$RMSE, probs = probs), min(x$results$RMSE))) +
    theme_bw()
}

tuneplot(xgb_tune)
xgb_tune$bestTune


tune_grid2 <- expand.grid(
  nrounds = seq(from = 50, to = nrounds, by = 50),
  eta = xgb_tune$bestTune$eta,
  max_depth = ifelse(xgb_tune$bestTune$max_depth == 6,
                     c(xgb_tune$bestTune$max_depth:7),
                     xgb_tune$bestTune$max_depth - 1:xgb_tune$bestTune$max_depth + 1),
  gamma = 0,
  colsample_bytree = 1,
  min_child_weight = c(1, 2, 3),
  subsample = 1
)

xgb_tune2 <- caret::train(
  quality ~ ., data = trainScaled,
  trControl = tune_control,
  tuneGrid = tune_grid2,
  method = "xgbTree",
  objective = "reg:squarederror", 
  eval_metric = "rmse",
  verbose = TRUE
)

tuneplot(xgb_tune2)
xgb_tune2$bestTune


tune_grid3 <- expand.grid(
  nrounds = seq(from = 50, to = nrounds, by = 50),
  eta = xgb_tune$bestTune$eta,
  max_depth = xgb_tune2$bestTune$max_depth,
  gamma = 0,
  colsample_bytree = c(0.4, 0.6, 0.8, 1.0),
  min_child_weight = xgb_tune2$bestTune$min_child_weight,
  subsample = c(0.5, 0.75, 1.0)
)

xgb_tune3 <- caret::train(
  quality ~ ., data = trainScaled,
  trControl = tune_control,
  tuneGrid = tune_grid3,
  method = "xgbTree",
  objective = "reg:squarederror", 
  eval_metric = "rmse",
  verbose = TRUE
)

tuneplot(xgb_tune3, probs = .95)


xgb_tune3$bestTune

tune_grid4 <- expand.grid(
  nrounds = seq(from = 50, to = nrounds, by = 50),
  eta = xgb_tune$bestTune$eta,
  max_depth = xgb_tune2$bestTune$max_depth,
  gamma = c(0, 0.05, 0.1, 0.5, 0.7, 0.9, 1.0),
  colsample_bytree = xgb_tune3$bestTune$colsample_bytree,
  min_child_weight = xgb_tune2$bestTune$min_child_weight,
  subsample = xgb_tune3$bestTune$subsample
)

xgb_tune4 <- caret::train(
  quality ~ ., data = trainScaled,
  trControl = tune_control,
  tuneGrid = tune_grid4,
  method = "xgbTree",
  verbose = TRUE
)

tuneplot(xgb_tune4)
xgb_tune4$bestTune

tune_grid5 <- expand.grid(
  nrounds = seq(from = 100, to = 10000, by = 100),
  eta = c(0.01, 0.015, 0.025, 0.05, 0.1),
  max_depth = xgb_tune2$bestTune$max_depth,
  gamma = xgb_tune4$bestTune$gamma,
  colsample_bytree = xgb_tune3$bestTune$colsample_bytree,
  min_child_weight = xgb_tune2$bestTune$min_child_weight,
  subsample = xgb_tune3$bestTune$subsample
)

xgb_tune5 <- caret::train(
  quality ~ ., data = trainScaled,
  trControl = tune_control,
  tuneGrid = tune_grid5,
  method = "xgbTree",
  objective = "reg:squarederror", 
  eval_metric = "rmse",
  verbose = TRUE
)

tuneplot(xgb_tune5)
xgb_tune5$bestTune


(final_grid <- expand.grid(
  nrounds = xgb_tune5$bestTune$nrounds,
  eta = xgb_tune5$bestTune$eta,
  max_depth = xgb_tune5$bestTune$max_depth,
  gamma = xgb_tune5$bestTune$gamma,
  colsample_bytree = xgb_tune5$bestTune$colsample_bytree,
  min_child_weight = xgb_tune5$bestTune$min_child_weight,
  subsample = xgb_tune5$bestTune$subsample
))

train_control <- caret::trainControl(
  method = "none",
  verboseIter = FALSE, # no training log
  allowParallel = TRUE # FALSE for reproducible results 
)

(xgb_model <- caret::train(
  quality ~ ., data = trainScaled,
  trControl = train_control,
  tuneGrid = final_grid,
  method = "xgbTree",
  objective = "reg:squarederror", 
  eval_metric = "rmse",
  verbose = TRUE
))

best_xgb_mod = predict(xgb_model, validationScaled[,-p])
best.xgb.myval = myval(best_xgb_mod, validationScaled$quality, title="Boosting: predicted vs true"); unlist(best.xgb.myval)




#LM with top variables
lm0 = glm(quality ~ alcohol + density + chlorides + volatile.acidity + total.sulfur.dioxide, data = trainScaled)
lm.fit.reduced = lm(quality~ alcohol + density + chlorides + volatile.acidity + total.sulfur.dioxide, data = trainScaled)
summary(lm.fit)
lm.pred.reduced = predict(lm0, validationScaled[,-p])
tr.lm.reduced.myval = myval(lm.pred.reduced, validationScaled$quality, "LM with best features: predicted vs true"); unlist(tr.lm.myval)


#GAM model with smoothing splines
# library(splines)
# fit = smooth.spline(trainScaled$density, trainScaled$quality,cv=TRUE)
# fit
# plot(trainScaled$residual.sugar, trainScaled$quality)
# lines(fit,col="red",lwd=2)
#I found optimal degrees of freedom for each variable and applied it. We see improvement
#in results
ga.model <- gam(quality ~ s(alcohol,12.23) + s(volatile.acidity,4) + s(sulphates,6.43) + s(chlorides,5.23) +
                  s(total.sulfur.dioxide,5.87) + s(free.sulfur.dioxide,8.5) +  s(citric.acid, 2) + s(pH,4.35) +
                  s(residual.sugar,23.16) + s(density,8) + s(fixed.acidity,4.3),
                data = trainScaled)
summary(ga.model)
gam_preds <- predict(ga.model, validationScaled[,-p])
tr.gam.myval = myval(gam_preds, validationScaled$quality, title="rf with CV: predicted vs true"); unlist(tr.gam.myval)



knitr::kable(cbind(lm = unlist(tr.lm.myval),
                   # lm.interac = unlist(tr.lm.interract.step.myval),
                   # lasso = unlist(tr.lasso.myval),
                   # ridge = unlist(tr.ridge.myval),
                   elastic.net = unlist(tr.elastic.myval),
                   rf.cv = unlist(tr.cvrf.myval),
                   lm.reduced = unlist(tr.lm.reduced.myval),
                   regression.tree = unlist(tr.rpart.myval),
                   # xgb = unlist(tr.xg.myval),
                   xgb_best = unlist(best.xgb.myval),
                   gam = unlist(tr.gam.myval)) ,
             
             
             caption = "Comparing all models from Session 1: ")

# dfcor <- cor(df)
# quality_cor <- dfcor[,12]
# absoutcome_cor <- abs(quality_cor)
# head(absoutcome_cor[order(absoutcome_cor, decreasing = TRUE)],12)

#fit best model (rf.cv) on TEST set and get predictions
tr.cvrf.off.pred = predict(tr.cvrf, testScale[,-p])
tr.cvrf.off.myval = myval(tr.cvrf.off.pred, testScale$quality, title="rf performance test set"); unlist(tr.cvrf.off.myval)



